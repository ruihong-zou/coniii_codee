{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c34e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# 仅在这个context里忽略警告\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    from coniii import *\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import Jangenerate_assembly #In the same dir\n",
    "import Jangenerate_SpikeCount #In the same dir\n",
    "from scipy.stats import poisson\n",
    "\n",
    "import itertools\n",
    "import time\n",
    "import math\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Define Parameters\n",
    "T = 3600 # time of simul“ation\n",
    "dT = 0.5 # time step\n",
    "params_assembly_num =5 # number of assemblies\n",
    "params_point_into_neuron_distance = 0.5 \n",
    "\n",
    "# Length of an active event as a number of timesteps\n",
    "eventDur = np.random.randint(1, 10)\n",
    "# Probability with which a unit is particularly active in a single timestep\n",
    "eventProb = np.random.uniform(0.01, 0.05)\n",
    "# Firing rate multiplier at active events\n",
    "eventMult = np.random.uniform(6, 10)  # random number between 1 and 5\n",
    "showPlot = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e50db4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryOutput(original_list):\n",
    "    # Create a new list to hold the tuples\n",
    "    tuples_list = []\n",
    "\n",
    "    # Generate all possible combinations of two elements for each sublist\n",
    "    for sublist in original_list:\n",
    "        combinations = itertools.combinations(sublist, 2)\n",
    "        # Convert the combinations into tuples and add them to the list\n",
    "        tuples_list.extend(tuple(sorted(combination)) for combination in combinations)\n",
    "\n",
    "    # Remove duplicates by converting the list to a set then back to a list\n",
    "    unique_tuples = list(set(tuples_list))\n",
    "    \n",
    "    return unique_tuples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7acffd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c432dfca9dc41818917ec5d54bd1d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7, 17), (12, 13), (3, 13), (12, 22), (9, 17), (19, 21), (11, 20), (13, 17), (18, 19), (10, 11), (9, 19), (10, 20), (7, 9), (13, 22), (18, 21), (3, 8), (12, 17), (9, 21), (8, 13), (17, 22), (9, 18)]\n",
      "_______________________________________\n",
      "[(24, 30), (13, 30), (6, 18), (15, 21), (26, 30), (18, 20), (18, 26), (15, 27), (20, 26), (20, 32), (18, 32), (21, 25), (5, 10), (14, 25), (23, 25), (1, 6), (28, 30), (11, 17), (24, 26), (13, 26), (6, 20), (15, 23), (26, 32), (4, 5), (6, 26), (6, 32), (4, 11), (21, 27), (14, 15), (14, 21), (4, 17), (23, 27), (0, 1), (0, 7), (10, 11), (14, 27), (10, 17), (6, 7), (24, 28), (13, 28), (15, 25), (25, 27), (26, 28), (21, 23), (4, 10), (5, 11), (14, 23), (5, 17), (0, 6), (1, 7), (13, 24)]\n",
      "_______________________________________\n"
     ]
    }
   ],
   "source": [
    "N = [25,36]\n",
    "params_assembly_density = [n // 6 for n in N] # size of neurons in each assembly\n",
    "\n",
    "assemblies_list = []\n",
    "spikeCount_list = []\n",
    "binary_list = []\n",
    "\n",
    "for i in tqdm(range (0, len(N))):\n",
    "    fire_rate_background = np.random.uniform(1, 6, N[i])\n",
    "    # Here's some preparatory code, we don't count its execution time\n",
    "    assemblies = Jangenerate_assembly.generate_assembly_solve(N[i], params_assembly_num, params_assembly_density[i])\n",
    "    # Output 0, 1 type spikes\n",
    "    spikeCount = Jangenerate_SpikeCount.generateSpikeCountSolve(N[i], T, dT, assemblies, (1, 6), eventDur, eventProb, eventMult, showPlot)\n",
    "    # Transform to -1, 1 distribution\n",
    "    spikeCount[spikeCount == 0] = -1\n",
    "    assemblies_list.append(assemblies)\n",
    "    spikeCount_list.append(spikeCount)\n",
    "    print(binaryOutput(assemblies))\n",
    "    print(\"_______________________________________\")\n",
    "    binary_list.append(binaryOutput(assemblies))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa179cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to encapsulate the code you want to time\n",
    "def code_to_time(spikeCount,threshold):\n",
    "    solver = ClusterExpansion(spikeCount, rng=np.random.RandomState(0))\n",
    "    multipliers, ent, clusters, deltaSdict, deltaJdict= solver.solve(threshold, full_output=True)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b079f9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989e6209078642b0b08746f017047c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(3, 8), (11, 20), (10, 11), (18, 19), (10, 20), (12, 22), (18, 21), (19, 21)} -- {(7, 17), (12, 13), (3, 13), (12, 22), (9, 17), (19, 21), (11, 20), (13, 17), (18, 19), (10, 11), (9, 19), (10, 20), (7, 9), (13, 22), (18, 21), (3, 8), (12, 17), (9, 21), (8, 13), (17, 22), (9, 18)} 0.38095238095238093\n",
      "--------------------\n",
      "{(13, 30), (15, 21), (24, 30), (18, 20), (15, 27), (20, 32), (18, 32), (21, 25), (5, 10), (14, 25), (23, 25), (28, 30), (11, 17), (15, 23), (4, 5), (4, 11), (4, 17), (14, 15), (14, 21), (21, 27), (0, 1), (0, 7), (23, 27), (10, 11), (14, 27), (10, 17), (13, 28), (15, 25), (24, 28), (25, 27), (21, 23), (4, 10), (5, 11), (14, 23), (5, 17), (1, 7), (13, 24)} -- {(24, 30), (6, 18), (15, 21), (13, 30), (26, 30), (18, 20), (18, 26), (15, 27), (20, 26), (20, 32), (18, 32), (21, 25), (5, 10), (14, 25), (23, 25), (1, 6), (28, 30), (11, 17), (24, 26), (13, 26), (6, 20), (15, 23), (26, 32), (4, 5), (6, 26), (6, 32), (4, 11), (21, 27), (14, 15), (14, 21), (4, 17), (23, 27), (0, 1), (0, 7), (10, 11), (14, 27), (10, 17), (6, 7), (24, 28), (13, 28), (15, 25), (25, 27), (26, 28), (21, 23), (4, 10), (5, 11), (14, 23), (5, 17), (0, 6), (1, 7), (13, 24)} 0.7254901960784313\n",
      "--------------------\n",
      "{(3, 8), (10, 11), (11, 20), (9, 19), (12, 17), (12, 13), (18, 19), (10, 20), (17, 22), (12, 22), (9, 18), (13, 22), (18, 21), (19, 21)} -- {(7, 17), (12, 13), (3, 13), (12, 22), (9, 17), (19, 21), (11, 20), (13, 17), (18, 19), (10, 11), (9, 19), (10, 20), (7, 9), (13, 22), (18, 21), (3, 8), (12, 17), (9, 21), (8, 13), (17, 22), (9, 18)} 0.6666666666666666\n",
      "--------------------\n",
      "{(13, 30), (6, 18), (15, 21), (24, 30), (26, 30), (18, 20), (15, 27), (18, 26), (20, 32), (18, 32), (21, 25), (5, 10), (14, 25), (23, 25), (28, 30), (11, 17), (24, 26), (15, 23), (6, 20), (4, 5), (6, 32), (4, 11), (4, 17), (14, 15), (14, 21), (21, 27), (0, 1), (0, 7), (23, 27), (10, 11), (14, 27), (10, 17), (13, 28), (15, 25), (24, 28), (25, 27), (26, 28), (21, 23), (4, 10), (5, 11), (14, 23), (5, 17), (1, 7), (13, 24)} -- {(24, 30), (6, 18), (15, 21), (13, 30), (26, 30), (18, 20), (18, 26), (15, 27), (20, 26), (20, 32), (18, 32), (21, 25), (5, 10), (14, 25), (23, 25), (1, 6), (28, 30), (11, 17), (24, 26), (13, 26), (6, 20), (15, 23), (26, 32), (4, 5), (6, 26), (6, 32), (4, 11), (21, 27), (14, 15), (14, 21), (4, 17), (23, 27), (0, 1), (0, 7), (10, 11), (14, 27), (10, 17), (6, 7), (24, 28), (13, 28), (15, 25), (25, 27), (26, 28), (21, 23), (4, 10), (5, 11), (14, 23), (5, 17), (0, 6), (1, 7), (13, 24)} 0.8627450980392157\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# 假设你已经有一个spikeCount_list和threshold\n",
    "threshold = [0.2, 0.15]\n",
    "\n",
    "# # 创建一个字典，用于存储每个阈值的结果\n",
    "results = {thresh: {'accuracy': []} for thresh in threshold}\n",
    "resultss = {thresh: {'time': []} for thresh in threshold}\n",
    "\n",
    "for thresh in tqdm(threshold):\n",
    "    iter_ratio = []\n",
    "    iter_times = []\n",
    "    for i in range(len(spikeCount_list)):\n",
    "        \n",
    "        \n",
    "        start_time = time.time()\n",
    "        # 执行你的函数\n",
    "        result = code_to_time(spikeCount_list[i], thresh)\n",
    "        end_time = time.time()\n",
    "        iter_times.append(end_time - start_time)\n",
    "\n",
    "        set1 = set([tuple(sublist) for sublist in result[2]])\n",
    "        set2 = set(binary_list[i])\n",
    "        # 计算重复度的比率\n",
    "        if len(set1) == 0:\n",
    "            dup_ratio = 0\n",
    "        else:\n",
    "            dup_ratio = len(set1 & set2) / len(set2)\n",
    "\n",
    "        iter_ratio.append(dup_ratio)\n",
    "        print(set1, \"--\",set2, dup_ratio)\n",
    "        print(\"--------------------\")\n",
    "\n",
    "        # 计算平均时间并添加到阈值的结果字典\n",
    "    results[thresh]['accuracy'].extend(iter_ratio)\n",
    "    resultss[thresh]['time'].extend(iter_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4d4eefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the text is negative\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "# 特征函数\n",
    "def feature_function(text, word):\n",
    "    # 计算文本中单词出现的次数\n",
    "    return text.count(word)\n",
    "\n",
    "# 模型预测\n",
    "def model_prediction(w, text, words):\n",
    "    return sigmoid(sum(w[i] * feature_function(text, word) for i, word in enumerate(words)))\n",
    "\n",
    "# 训练数据\n",
    "texts = [\"I love this movie\", \"I hate this movie\", \"This movie is great\", \"This movie is terrible\"]\n",
    "labels = [1, 0, 1, 0]  # 1表示积极情感，0表示消极情感\n",
    "\n",
    "# 特征词列表\n",
    "words = [\"love\", \"hate\", \"great\", \"terrible\"]\n",
    "\n",
    "# 初始化权重\n",
    "w = np.random.normal(size=len(words))\n",
    "\n",
    "# 梯度上升法\n",
    "learning_rate = 0.01\n",
    "for step in range(1000):\n",
    "    # 在每一步迭代中，我们随机选择一个样本进行更新\n",
    "    i = np.random.randint(len(texts))\n",
    "    text = texts[i]\n",
    "    label = labels[i]\n",
    "    \n",
    "    # 计算模型的预测和实际观察到的差异\n",
    "    prediction = model_prediction(w, text, words)\n",
    "    error = prediction - label\n",
    "    \n",
    "    # 计算梯度并更新权重\n",
    "    for j, word in enumerate(words):\n",
    "        gradient = error * feature_function(text, word)\n",
    "        w[j] = w[j] - learning_rate * gradient\n",
    "\n",
    "# 预测新的文本的情感\n",
    "new_text = \"This movie is hate\"\n",
    "prediction = model_prediction(w, new_text, words)\n",
    "print(\"The sentiment of the text is positive\" if prediction > 0.5 else \"The sentiment of the text is negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a97590",
   "metadata": {},
   "source": [
    "模型的预测值（由model_prediction函数计算）尽可能接近观察到的平均值（observed_mean），"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "063913ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomState(MT19937) at 0x1AE3FC81B40"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1338315c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coniii",
   "language": "python",
   "name": "coniii"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
